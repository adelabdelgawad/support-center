services:
  # PostgreSQL Database
  postgres:
    image: postgres:18.1-alpine3.23
    container_name: supportcenter-postgres
    env_file:
      - docker/env/.env.postgres
    volumes:
      - ~/workspace/docker/it_support_center/postgres:/var/lib/postgresql/data
    ports:
      - "${POSTGRES_PORT:-5433}:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U servicecatalog"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supportcenter-network
    restart: unless-stopped

  # PgBouncer - Connection Pooler for Horizontal Scaling
  pgbouncer:
    image: edoburu/pgbouncer:latest
    container_name: supportcenter-pgbouncer
    environment:
      - DATABASE_URL=postgres://${PGBOUNCER_DB_USER:-servicecatalog}:${PGBOUNCER_DB_PASSWORD:-servicecatalog}@postgres:5432/${PGBOUNCER_DB_NAME:-servicecatalog}
      - POOL_MODE=transaction
      - DEFAULT_POOL_SIZE=50
      - MAX_CLIENT_CONN=500
      - MAX_DB_CONNECTIONS=100
      - SERVER_RESET_QUERY=DISCARD ALL
      - IGNORE_STARTUP_PARAMETERS=extra_float_digits
    ports:
      - "127.0.0.1:${PGBOUNCER_PORT:-6432}:5432"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h 127.0.0.1 -p 5432 -U ${PGBOUNCER_DB_USER:-servicecatalog}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supportcenter-network
    restart: unless-stopped

  # Redis for Caching and Pub/Sub (Scaled for 1000+ connections)
  redis:
    image: redis:8.6-rc1-alpine3.23
    container_name: supportcenter-redis
    env_file:
      - docker/env/.env.redis
    command: sh -c 'redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru --appendonly yes --notify-keyspace-events Ex --maxclients 10000 --timeout 0 --tcp-keepalive 300 --requirepass $$REDIS_PASSWORD'
    volumes:
      - ~/workspace/docker/it_support_center/redis:/data
    ports:
      - "127.0.0.1:${REDIS_PORT:-6380}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supportcenter-network
    restart: unless-stopped

  # MinIO Object Storage
  # SECURITY (Finding #38): MinIO is isolated on internal network only
  # No ports are exposed to host - only accessible from backend containers
  minio:
    image: minio/minio:latest
    container_name: supportcenter-minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"  # Expose for local development (backend runs on host)
      - "9001:9001"  # Console for administration
    env_file:
      - docker/env/.env.minio
    volumes:
      - ~/workspace/docker/it_support_center/minio:/data
    # SECURITY: Removed port exposure - access only via internal Docker network
    # To access MinIO console for administration, use:
    #   docker exec -it servicecatalog_minio mc admin info local
    # Or temporarily add ports back for debugging
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supportcenter-minio-network  # Internal network only
    restart: unless-stopped

  # FastAPI Backend Instance 1 (Primary)
  backend-1:
    build:
      context: ./src/backend
      dockerfile: ../../docker/backend/Dockerfile
    container_name: supportcenter-backend-1
    environment:
      - INSTANCE_ID=backend-1
    env_file:
      - docker/env/.env.backend
    volumes:
      - ~/workspace/docker/it_support_center/backend/uploads:/app/uploads
      - ~/workspace/docker/it_support_center/backend/temp_uploads:/app/temp_uploads
    ports:
      - "${BACKEND_PORT_1:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - supportcenter-network
      - supportcenter-minio-network  # SECURITY (Finding #38): Access to isolated MinIO
    restart: unless-stopped

  # FastAPI Backend Instance 2
  backend-2:
    build:
      context: ./src/backend
      dockerfile: ../../docker/backend/Dockerfile
    container_name: supportcenter-backend-2
    environment:
      - INSTANCE_ID=backend-2
    env_file:
      - docker/env/.env.backend
    volumes:
      - ~/workspace/docker/it_support_center/backend/uploads:/app/uploads
      - ~/workspace/docker/it_support_center/backend/temp_uploads:/app/temp_uploads
    ports:
      - "${BACKEND_PORT_2:-8001}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - supportcenter-network
      - supportcenter-minio-network  # SECURITY (Finding #38): Access to isolated MinIO
    restart: unless-stopped

  # FastAPI Backend Instance 3
  backend-3:
    build:
      context: ./src/backend
      dockerfile: ../../docker/backend/Dockerfile
    container_name: supportcenter-backend-3
    environment:
      - INSTANCE_ID=backend-3
    env_file:
      - docker/env/.env.backend
    volumes:
      - ~/workspace/docker/it_support_center/backend/uploads:/app/uploads
      - ~/workspace/docker/it_support_center/backend/temp_uploads:/app/temp_uploads
    ports:
      - "${BACKEND_PORT_3:-8002}:8000"
    depends_on:
      postgres:
        condition: service_healthy
      pgbouncer:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - supportcenter-network
      - supportcenter-minio-network  # SECURITY (Finding #38): Access to isolated MinIO
    restart: unless-stopped

  # Celery Worker
  celery_worker:
    build:
      context: ./src/backend
      dockerfile: ../../docker/backend/Dockerfile
    container_name: supportcenter-celery-worker
    command: celery -A celery_app worker --loglevel=info --concurrency=4 -Q celery,file_queue,ad_queue
    env_file:
      - docker/env/.env.backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ~/workspace/docker/it_support_center/backend/temp_uploads:/app/temp_uploads
    healthcheck:
      test: ["CMD-SHELL", "celery -A celery_app inspect ping -d celery@$$HOSTNAME || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - supportcenter-network
      - supportcenter-minio-network  # SECURITY (Finding #38): Access to isolated MinIO
    restart: unless-stopped

  # Next.js Frontend
  frontend:
    build:
      context: ./src/it-app
      dockerfile: ../../docker/frontend/Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://backend-1:8000}
        - NEXT_PUBLIC_API_BASE_PATH=${NEXT_PUBLIC_API_BASE_PATH:-/api/v1}
        - NEXT_PUBLIC_SIGNALR_URL=${NEXT_PUBLIC_SIGNALR_URL:-http://signalr-service:5000/hubs}
    container_name: supportcenter-frontend
    env_file:
      - docker/env/.env.frontend
    ports:
      - "${FRONTEND_PORT:-3010}:3010"
    depends_on:
      backend-1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:3010/api/health', (r) => process.exit(r.statusCode === 200 ? 0 : 1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - supportcenter-network
    restart: unless-stopped

  # Prometheus - Metrics Collection and Monitoring
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: supportcenter-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--storage.tsdb.retention.size=10GB'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    volumes:
      - ./docker/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./docker/monitoring/prometheus/alerts:/etc/prometheus/alerts:ro
      - ./docker/monitoring/prometheus/rules:/etc/prometheus/rules:ro
      - ~/workspace/docker/it_support_center/prometheus:/prometheus
    ports:
      - "127.0.0.1:${PROMETHEUS_PORT:-9090}:9090"
    networks:
      - supportcenter-network
    restart: unless-stopped
    depends_on:
      - backend-1
      - backend-2
      - backend-3
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # Grafana - Metrics Visualization and Dashboards
  grafana:
    image: grafana/grafana:10.2.2
    container_name: supportcenter-grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-grafana_admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-ChangeMeInProd2024!}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_AUTH_ANONYMOUS_ENABLED=false
      - GF_SERVER_ROOT_URL=http://localhost:3030
      - GF_INSTALL_PLUGINS=
    volumes:
      - ./docker/monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./docker/monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ~/workspace/docker/it_support_center/grafana:/var/lib/grafana
    ports:
      - "127.0.0.1:${GRAFANA_PORT:-3030}:3000"
    networks:
      - supportcenter-network
    restart: unless-stopped
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # CoTURN TURN Server for WebRTC NAT Traversal
  coturn:
    image: coturn/coturn:latest
    container_name: supportcenter-coturn
    network_mode: host  # Use host networking to avoid port mapping issues
    env_file:
      - docker/env/.env.coturn
    volumes:
      - ./docker/coturn/turnserver.conf:/etc/coturn/turnserver.conf:ro
    restart: unless-stopped
    command:
      - "-c"
      - "/etc/coturn/turnserver.conf"
      - "--listening-ip=$$TURN_LISTENING_IP"
      - "--relay-ip=$$TURN_RELAY_IP"
      - "--external-ip=$$TURN_EXTERNAL_IP"
      - "--lt-cred-mech"
      - "--use-auth-secret"
      - "--static-auth-secret=$$TURN_SECRET"
      - "--realm=$$TURN_REALM"
      - "-v"
    healthcheck:
      test: ["CMD-SHELL", "ss -lun | grep -q ':3478'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # SignalR Service for Real-time Communication
  signalr-service:
    build:
      context: .
      dockerfile: docker/signalr-service/Dockerfile
    container_name: supportcenter-signalr
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - INTERNAL_API_KEY=${SIGNALR_INTERNAL_API_KEY}
      - ASPNETCORE_ENVIRONMENT=${ASPNETCORE_ENVIRONMENT:-Production}
      - EnableRedisBackplane=${SIGNALR_ENABLE_REDIS_BACKPLANE:-false}
    ports:
      - "${SIGNALR_PORT:-5000}:5000"
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - supportcenter-network
    restart: unless-stopped

  # Nginx Reverse Proxy with SSL/TLS
  nginx:
    image: nginx:alpine
    container_name: supportcenter-nginx
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - ./docker/nginx/acme-challenge:/var/www/acme-challenge:ro
    ports:
      - "80:80"
      - "443:443"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - supportcenter-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "sh", "-c", "nc -zv 127.0.0.1 443 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  supportcenter-network:
    driver: bridge

  # SECURITY (Finding #38): Isolated internal network for MinIO object storage
  # MinIO is placed on this internal-only network to prevent direct access from:
  # - Host system (no port exposure)
  # - Other containers that don't need storage access
  # Only backend services and celery workers are connected to this network
  supportcenter-minio-network:
    driver: bridge
    internal: true  # No external connectivity - internal Docker network only
